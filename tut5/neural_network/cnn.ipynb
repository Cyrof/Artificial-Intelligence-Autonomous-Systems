{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Building a Neural Network Model in PyTorch\n", "### Import required packages"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch \n", "import torch.nn as nn"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Define the Neural Network Architecture"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class NNM(nn.Module):\n", "    def __init__(self):\n", "        super(NNM, self).__init__()\n", "        # define neural network architecture \n", "        self.layer1 = nn.Linear(8, 16) # Input layer to hidden layer\n", "        self.layer2 = nn.Linear(16, 12) # Hidden layer to hidden layer \n", "        self.layer3 = nn.Linear(12, 1) # Hidden layer to output layer \n", "        self.relu = nn.ReLU() # Activation function \n", "\n", "    def forward(self, x):\n", "        # define the forward pass of the neural network \n", "        x = self.layer1(x)\n", "        x = self.relu(x)\n", "        x = self.layer2(x)\n", "        x = self.relu(x)\n", "        x = self.layer3(x)\n", "        x = torch.sigmoid(x) # use sigmoid for binary classification\n", "        return x\n", "\n", "# Create an instance of the model \n", "cnn = NNM()\n", "cnn"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Explaination of forward function\n", "The forward function in a PyTorch nerual network defined the forward pass of the network. This is where you specify how the input tensor is transformed as it passes through each layer of the network. During training and testing, the forward function is called automatically when you pass input data to the model. \n", "\n", "### How it works: \n", "**Input Transformation:** The input data is passed through the defined layers in the `__init__` method.\n", "**Activation Function:** Activation functions like `ReLU` are applied to intruduce non-linearity.\n", "**Output Generation:** The final output is computed, which can be passed to a loss function during training or compared with the actual labels during testing.\n", "\n", "When training, the forward pass computes the predicted output, and the loss between the predicted and actual outputs in calculated. This loss is then used to update the model weights during backpropagation. When testing, the forward pass computes the output for the test data, which is used to evaluate the model's performance. \n", "\n", "### Difference Between Supervised Learning and Unsupervised Learning\n", "**Supervised LEarning**\n", "In supervised learning, the model is trained on labeled data. This means that each training example is paired with an output label. The model learns to map inputs to the correct outputs based on these labeled examples. \n", "\n", "**Example:**\n", "- **Application:** Image Classification\n", "- **Explanation:** A model is trained to classify images into different categories (e.g., cats vs dogs) using a labeled dataset where each image is tagged with the correct category.\n", "\n", "**Unsupervised Learning**\n", "In unsupervised learning, the model is trained on unlabeled data. The model tries to find patterns and relationships in the data without any explicit output labels.\n", "\n", "**Example:**\n", "- **Application:** Customer Segmentation\n", "- **Explanation:** A model is used to segment customers into different groups based on purchasing behavior without any prior labels. This can help in identif"]}], "metadata": {"kernelspec": {"display_name": "Python (lab5)", "language": "python", "name": "lab5"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.4"}}, "nbformat": 4, "nbformat_minor": 4}
